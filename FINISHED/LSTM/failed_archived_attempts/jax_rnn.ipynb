{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import optax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lmao maol\n"
     ]
    }
   ],
   "source": [
    "# set up and process data\n",
    "sequence_length = 4 #lmao -> maol => l\n",
    "raw_train_data = \"lmao\" * 1000 # lmao\n",
    "\n",
    "vocab = sorted(list(set(raw_train_data)))\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "\n",
    "translations = {\n",
    "  \"encode\" : dict([(c, t) for c, t in zip(vocab, range(len(vocab)))]),\n",
    "  \"decode\" : dict([(t, c) for c, t in zip(vocab, range(len(vocab)))])\n",
    "}\n",
    "\n",
    "token = lambda c: translations[\"encode\"][c] # char to token\n",
    "char = lambda t: translations[\"decode\"][int(t)] # token to char\n",
    "encode = lambda cs: jnp.array([token(c) for c in cs])\n",
    "decode = lambda ts: \"\".join([char(t) for t in ts])\n",
    "\n",
    "train_data_tokens = encode(raw_train_data)\n",
    "x_train_tokens = [jnp.array(train_data_tokens[i:i+sequence_length]) for i in range(len(train_data_tokens))] # 0,1,2,3\n",
    "y_train_tokens = [jnp.array(train_data_tokens[i+1:i+sequence_length+1]) for i in range(len(train_data_tokens) - 1)] # 1,2,3,4\n",
    "print(decode(x_train_tokens[0]), decode(y_train_tokens[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "experiment:\n",
    "get my posts\n",
    "input: nothing\n",
    "output: a post\n",
    "\n",
    "experiment:\n",
    "video generator\n",
    "input: blank transparent canvas\n",
    "output: the next frame of the video\n",
    "do a several convolution skip connections on each step (adds changes to each frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.0532193 maol aolm\n",
      "50 1.443141 maol aolm\n",
      "100 0.12231689 olma lmao\n",
      "150 0.77888703 lmao maol\n",
      "200 0.24667618 olma lmao\n",
      "250 0.18515052 lmao maol\n",
      "300 0.29211754 maol aolm\n",
      "350 0.08199807 olma lmao\n",
      "400 0.061798505 lmao maol\n",
      "450 0.08337262 olma lmao\n",
      "500 1.4406747 aolm olma\n",
      "550 0.02647544 lmao maol\n",
      "600 0.08650149 maol aolm\n",
      "650 0.02113651 lmao maol\n",
      "700 0.04582143 maol aolm\n",
      "750 1.4037068 aolm olma\n",
      "800 1.4018327 aolm olma\n",
      "850 1.3933158 aolm olma\n",
      "900 0.0059581455 olma lmao\n",
      "950 0.021258852 maol aolm\n"
     ]
    }
   ],
   "source": [
    "# init rnn params\n",
    "# inputs ()\n",
    "def init_rnn_params(key, input_shape, hidden_shape, output_shape):\n",
    "  keys = random.split(key, 20)\n",
    "  rnn_params = {\n",
    "    # xW means shape of W is (input, output)\n",
    "    # hW and xW should output the shape of h.\n",
    "    \"Whh\" : random.normal(keys[0], shape=(hidden_shape[0], hidden_shape[0])) * jnp.sqrt(2 / hidden_shape[0]),\n",
    "    \"Whx\" : random.normal(keys[1], shape=(input_shape[0], hidden_shape[0])) * jnp.sqrt(2 / input_shape[0]),\n",
    "    \"Why\" : random.normal(keys[2], shape=(hidden_shape[0], output_shape[0])) * jnp.sqrt(2 / hidden_shape[0])\n",
    "  }\n",
    "  return rnn_params\n",
    "\n",
    "\n",
    "def step_start(rnn_params, x):\n",
    "  hidden_shape = rnn_params[\"Whh\"].shape[0]\n",
    "  h = jnp.zeros(hidden_shape)\n",
    "  y, h = step(rnn_params, h, x)\n",
    "  return y, h\n",
    "\n",
    "def step(rnn_params, h, x):\n",
    "  z = h @ rnn_params[\"Whh\"] + x @ rnn_params[\"Whx\"]\n",
    "  h = jax.nn.tanh(z)\n",
    "\n",
    "  y = h @ rnn_params[\"Why\"]\n",
    "  return y, h\n",
    "\n",
    "# choose to get output if you want. update() always returns it but it may not be used.\n",
    "#\n",
    "# update(h, x0) ----- update(h, x0) ----- update(h) ----- update(h, x2)\n",
    "#   |                        |                                   |\n",
    "#   |                        |                                   |\n",
    "# step(x0)               step(x1)           step()           step(x2)\n",
    "\n",
    "\n",
    "def forward(rnn_params, xbow):\n",
    "  # for now, recreate karpathy's example\n",
    "  # lma -> mao\n",
    "  y0, h = step_start(rnn_params, xbow[0])\n",
    "  y1, h = step(rnn_params, h, xbow[1])\n",
    "  y2, h = step(rnn_params, h, xbow[2])\n",
    "  y3, h = step(rnn_params, h, xbow[3])\n",
    "  return jnp.array([y0, y1, y2, y3])\n",
    "\n",
    "\n",
    "def init_embedding_params(key, model_dim):\n",
    "  keys = random.split(key, 10)\n",
    "  embedding_params = {\n",
    "    \"layer_1\" : {\n",
    "      \"w\" : random.normal(keys[0], shape=(1, model_dim)),\n",
    "      \"b\" : jnp.zeros((model_dim,)),\n",
    "      }\n",
    "  }\n",
    "  return embedding_params\n",
    "\n",
    "def embed_tokens(embedding_params, tokens):\n",
    "  # ts[:, None] turns it from [t, t, t, t] to [[t], [t], [t], [t]]. as it should be, a row vector. transpose but for 1d vec.\n",
    "  x = tokens[:, None] @ embedding_params[\"layer_1\"][\"w\"] + embedding_params[\"layer_1\"][\"b\"]\n",
    "  x = jax.nn.relu(x)\n",
    "  return x\n",
    "\n",
    "def embed_chars(embedding_params, chars):\n",
    "  tokens = encode(chars)\n",
    "  return embed_tokens(embedding_params, tokens)\n",
    "\n",
    "def get_loss(rnn_params, xtokens, ytokens):\n",
    "  xbow = embed_tokens(rnn_params[\"embedding_params\"], xtokens)\n",
    "  logits = forward(rnn_params, xbow)\n",
    "  ytokens_one_hot = jax.nn.one_hot(ytokens, len(logits[0]))\n",
    "  cross_entropies = -jnp.sum(jax.nn.log_softmax(logits, axis=-1) * ytokens_one_hot, axis=-1)\n",
    "  net_cross_entropy_loss = jnp.sum(cross_entropies)\n",
    "  return net_cross_entropy_loss\n",
    "\n",
    "\n",
    "\n",
    "def train_step(rnn_params, xtokens, ytokens, optimizer, opt_state):\n",
    "  loss, grads = jax.value_and_grad(get_loss)(rnn_params, xtokens, ytokens)\n",
    "  param_updates, updated_opt_state = optimizer.update(grads, opt_state)\n",
    "  updated_params = optax.apply_updates(rnn_params, param_updates)\n",
    "  return loss, updated_params, updated_opt_state\n",
    "\n",
    "\n",
    "\n",
    "# setup\n",
    "keys = random.split(random.PRNGKey(198123), 10)\n",
    "\n",
    "model_dim = 16 # C\n",
    "input_shape = (model_dim,)\n",
    "hidden_shape = (20,)\n",
    "output_shape = (vocab_size,) # logits\n",
    "\n",
    "embedding_params = init_embedding_params(keys[0], model_dim)\n",
    "\n",
    "rnn_params = init_rnn_params(keys[1], input_shape, hidden_shape, output_shape)\n",
    "rnn_params.update({\"embedding_params\" : embedding_params})\n",
    "\n",
    "lr = 0.01\n",
    "optimizer = optax.adam(lr)\n",
    "opt_state = optimizer.init(rnn_params)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "xbow = embed_chars(rnn_params[\"embedding_params\"], \"lmao\")\n",
    "ytokens = encode(\"maoo\")\n",
    "\n",
    "indices = random.permutation(keys[3], len(x_train_tokens))\n",
    "\n",
    "steps = 1000\n",
    "print_every = 50\n",
    "for i in range(steps):\n",
    "  idx = indices[i]\n",
    "  xtokens = x_train_tokens[idx]\n",
    "  ytokens = y_train_tokens[idx]\n",
    "  loss, rnn_params, opt_state = train_step(rnn_params, xtokens, ytokens, optimizer, opt_state)\n",
    "  if i % print_every == 0:\n",
    "    print(i, loss, decode(xtokens), decode(ytokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lmaolmaolmaolmaolmaolmaolmaolmaolmaolmaolmaolmaolmaolmaolmaolmaolmaolmaolmaolmaolmaolmaolmaolmaolmaolmao"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def inference(rnn_params, xchars):\n",
    "  xbow = embed_chars(rnn_params[\"embedding_params\"], xchars)\n",
    "  logits = forward(rnn_params, xbow)\n",
    "  yhatbow = jnp.argmax(logits, axis=-1)\n",
    "  yhatbow_chars = decode(yhatbow)\n",
    "  return yhatbow_chars\n",
    "\n",
    "text = \"lmao\"\n",
    "print(text, end='')\n",
    "for i in range(100):\n",
    "  current_input = text[-sequence_length:] # final $seq_length chars\n",
    "  next_char = inference(rnn_params, current_input)[-1]\n",
    "  text += next_char\n",
    "  print(next_char, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
