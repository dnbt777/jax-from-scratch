{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6938, Accuracy: 0.7916\n",
      "Epoch 2, Loss: 0.3918, Accuracy: 0.9053\n",
      "Epoch 3, Loss: 0.5479, Accuracy: 0.8582\n",
      "Epoch 4, Loss: 0.4336, Accuracy: 0.9182\n",
      "Epoch 5, Loss: 0.2932, Accuracy: 0.9292\n",
      "Epoch 6, Loss: 0.3755, Accuracy: 0.9213\n",
      "Epoch 7, Loss: 0.3928, Accuracy: 0.9186\n",
      "Epoch 8, Loss: 0.4687, Accuracy: 0.9205\n",
      "Epoch 9, Loss: 0.9370, Accuracy: 0.7455\n",
      "Epoch 10, Loss: 0.8330, Accuracy: 0.7128\n",
      "Epoch 11, Loss: 0.9690, Accuracy: 0.6544\n",
      "Epoch 12, Loss: 0.8165, Accuracy: 0.6888\n",
      "Epoch 13, Loss: 0.7127, Accuracy: 0.7513\n",
      "Epoch 14, Loss: 0.6788, Accuracy: 0.7712\n",
      "Epoch 15, Loss: 1.2492, Accuracy: 0.5151\n",
      "Epoch 16, Loss: 0.9478, Accuracy: 0.6216\n",
      "Epoch 17, Loss: 0.9827, Accuracy: 0.5879\n",
      "Epoch 18, Loss: 1.2964, Accuracy: 0.4739\n",
      "Epoch 19, Loss: 1.4637, Accuracy: 0.4333\n",
      "Epoch 20, Loss: 1.1621, Accuracy: 0.5499\n",
      "Epoch 21, Loss: 1.6922, Accuracy: 0.2813\n",
      "Epoch 22, Loss: 1.7020, Accuracy: 0.2791\n",
      "Epoch 23, Loss: 1.9011, Accuracy: 0.2376\n",
      "Epoch 24, Loss: 1.6968, Accuracy: 0.2785\n",
      "Epoch 25, Loss: 1.7327, Accuracy: 0.2875\n",
      "Epoch 26, Loss: 1.6867, Accuracy: 0.2929\n",
      "Epoch 27, Loss: 1.8957, Accuracy: 0.2507\n",
      "Epoch 28, Loss: 1.7343, Accuracy: 0.2714\n",
      "Epoch 29, Loss: 1.6909, Accuracy: 0.2913\n",
      "Epoch 30, Loss: 1.9738, Accuracy: 0.2361\n",
      "Epoch 31, Loss: 1.9055, Accuracy: 0.2609\n",
      "Epoch 32, Loss: 1.8356, Accuracy: 0.2844\n",
      "Epoch 33, Loss: 2.1088, Accuracy: 0.1765\n",
      "Epoch 34, Loss: 2.2541, Accuracy: 0.1206\n",
      "Epoch 35, Loss: 2.2989, Accuracy: 0.1130\n",
      "Epoch 36, Loss: 2.3002, Accuracy: 0.1130\n",
      "Epoch 37, Loss: 1.8848, Accuracy: 0.2783\n",
      "Epoch 38, Loss: 1.8101, Accuracy: 0.2853\n",
      "Epoch 39, Loss: 1.7890, Accuracy: 0.2780\n",
      "Epoch 40, Loss: 1.9307, Accuracy: 0.2449\n",
      "Epoch 41, Loss: 1.8201, Accuracy: 0.2745\n",
      "Epoch 42, Loss: 1.9071, Accuracy: 0.2456\n",
      "Epoch 43, Loss: 1.8618, Accuracy: 0.2758\n",
      "Epoch 44, Loss: 1.7860, Accuracy: 0.2592\n",
      "Epoch 45, Loss: 1.7048, Accuracy: 0.2880\n",
      "Epoch 46, Loss: 1.6820, Accuracy: 0.2846\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 97\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, total_samples, batch_size):\n\u001b[1;32m     96\u001b[0m     X_batch \u001b[38;5;241m=\u001b[39m X_train_shuffled[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[0;32m---> 97\u001b[0m     y_batch \u001b[38;5;241m=\u001b[39m \u001b[43my_train_onehot_shuffled\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     99\u001b[0m     opt_params, opt_state \u001b[38;5;241m=\u001b[39m update_fn(opt_params, opt_state, X_batch, y_batch)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# Compute loss and accuracy on the full training set\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ai_gym/.venv/lib/python3.10/site-packages/jax/_src/array.py:370\u001b[0m, in \u001b[0;36mArrayImpl.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    365\u001b[0m       out \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39msqueeze(out, dimensions\u001b[38;5;241m=\u001b[39mdims)\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArrayImpl(\n\u001b[1;32m    368\u001b[0m         out\u001b[38;5;241m.\u001b[39maval, sharding, [out], committed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, _skip_checks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlax_numpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rewriting_take\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ai_gym/.venv/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:11396\u001b[0m, in \u001b[0;36m_rewriting_take\u001b[0;34m(arr, idx, indices_are_sorted, unique_indices, mode, fill_value)\u001b[0m\n\u001b[1;32m  11387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_rewriting_take\u001b[39m(arr, idx, indices_are_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, unique_indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m  11388\u001b[0m                     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m  11389\u001b[0m   \u001b[38;5;66;03m# Computes arr[idx].\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11393\u001b[0m   \u001b[38;5;66;03m# For simplicity of generated primitives, we call lax.dynamic_slice in the\u001b[39;00m\n\u001b[1;32m  11394\u001b[0m   \u001b[38;5;66;03m# simplest cases: i.e. non-dynamic arrays indexed with integers and slices.\u001b[39;00m\n\u001b[0;32m> 11396\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (result \u001b[38;5;241m:=\u001b[39m \u001b[43m_attempt_rewriting_take_via_slice\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m  11397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m  11399\u001b[0m   \u001b[38;5;66;03m# TODO(mattjj,dougalm): expand dynamic shape indexing support\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ai_gym/.venv/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:11373\u001b[0m, in \u001b[0;36m_attempt_rewriting_take_via_slice\u001b[0;34m(arr, idx, mode)\u001b[0m\n\u001b[1;32m  11371\u001b[0m   int_start_indices \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m start_indices]  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m  11372\u001b[0m   int_limit_indices \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;241m+\u001b[39m s \u001b[38;5;28;01mfor\u001b[39;00m i, s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(int_start_indices, slice_sizes)]\n\u001b[0;32m> 11373\u001b[0m   arr \u001b[38;5;241m=\u001b[39m \u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslice\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11374\u001b[0m \u001b[43m      \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mint_start_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mint_limit_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m  11375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m  11376\u001b[0m   \u001b[38;5;66;03m# We must be careful with dtypes because dynamic_slice requires all\u001b[39;00m\n\u001b[1;32m  11377\u001b[0m   \u001b[38;5;66;03m# start indices to have matching types.\u001b[39;00m\n\u001b[1;32m  11378\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(start_indices) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/ai_gym/.venv/lib/python3.10/site-packages/jax/_src/lax/slicing.py:107\u001b[0m, in \u001b[0;36mslice\u001b[0;34m(operand, start_indices, limit_indices, strides)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mslice\u001b[39m(operand: ArrayLike, start_indices: Sequence[\u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m     57\u001b[0m           limit_indices: Sequence[\u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m     58\u001b[0m           strides: Sequence[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Array:\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Wraps XLA's `Slice\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m  <https://www.tensorflow.org/xla/operation_semantics#slice>`_\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m  operator.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m    - :func:`jax.lax.dynamic_slice`\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mslice_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstart_indices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mlimit_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlimit_indices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ai_gym/.venv/lib/python3.10/site-packages/jax/_src/core.py:438\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[1;32m    436\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39menable_checks\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    437\u001b[0m           \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(arg, Tracer) \u001b[38;5;129;01mor\u001b[39;00m valid_jaxtype(arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)), args\n\u001b[0;32m--> 438\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfind_top_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ai_gym/.venv/lib/python3.10/site-packages/jax/_src/core.py:442\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[1;32m    441\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m pop_level(trace\u001b[38;5;241m.\u001b[39mlevel):\n\u001b[0;32m--> 442\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_raise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(full_lower, out) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiple_results \u001b[38;5;28;01melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[0;32m~/Desktop/ai_gym/.venv/lib/python3.10/site-packages/jax/_src/core.py:955\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    953\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m call_impl_with_key_reuse_checks(primitive, primitive\u001b[38;5;241m.\u001b[39mimpl, \u001b[38;5;241m*\u001b[39mtracers, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 955\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprimitive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtracers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ai_gym/.venv/lib/python3.10/site-packages/jax/_src/lax/slicing.py:1329\u001b[0m, in \u001b[0;36m_slice_impl\u001b[0;34m(x, start_indices, limit_indices, strides)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch\u001b[38;5;241m.\u001b[39mapply_primitive(\n\u001b[1;32m   1326\u001b[0m     slice_p, x, start_indices\u001b[38;5;241m=\u001b[39mstart_indices,\n\u001b[1;32m   1327\u001b[0m     limit_indices\u001b[38;5;241m=\u001b[39mlimit_indices, strides\u001b[38;5;241m=\u001b[39mstrides)\n\u001b[1;32m   1328\u001b[0m slice_sizes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(np\u001b[38;5;241m.\u001b[39marray(limit_indices) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39marray(start_indices))\n\u001b[0;32m-> 1329\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdynamic_slice_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstart_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mslice_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslice_sizes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ai_gym/.venv/lib/python3.10/site-packages/jax/_src/dispatch.py:91\u001b[0m, in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m     89\u001b[0m prev \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mjax_jit\u001b[38;5;241m.\u001b[39mswap_thread_local_state_disable_jit(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 91\u001b[0m   outs \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m   lib\u001b[38;5;241m.\u001b[39mjax_jit\u001b[38;5;241m.\u001b[39mswap_thread_local_state_disable_jit(prev)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "import optax\n",
    "\n",
    "# Hyperparameters\n",
    "neurons = [28*28, 28*28, 28*28, 28*28, 28*28, 10]\n",
    "lr = 0.01\n",
    "batch_size = 8\n",
    "total_samples = 60000\n",
    "epochs = 1000\n",
    "\n",
    "# Load MNIST data using PyTorch\n",
    "transform = transforms.Compose([transforms.ToTensor(), lambda x: torch.flatten(x)])\n",
    "mnist_train = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "\n",
    "# Select a subset of 40 samples\n",
    "subset_idx = torch.randperm(len(mnist_train))   #[ :total_samples]\n",
    "train_data = [(mnist_train[i][0].numpy(), mnist_train[i][1]) for i in subset_idx]\n",
    "\n",
    "# Prepare data\n",
    "X_train = jnp.array([x[0] for x in train_data])  # Shape: (40, 28*28)\n",
    "y_train = jnp.array([x[1] for x in train_data])  # Shape: (40,)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train_onehot = jax.nn.one_hot(y_train, num_classes=10)\n",
    "\n",
    "# Initialize weights and biases\n",
    "key = random.PRNGKey(0)\n",
    "params = []\n",
    "for in_dim, out_dim in zip(neurons[:-1], neurons[1:]):\n",
    "    k1, key = random.split(key)\n",
    "    W = random.normal(k1, (in_dim, out_dim)) * jnp.sqrt(2 / in_dim)\n",
    "    b = jnp.zeros(out_dim)\n",
    "    params.append((W, b))\n",
    "\n",
    "# Convert params into a single structure for Optax\n",
    "def flatten_params(params):\n",
    "    flat = {\"layer_\" + str(i): {\"W\": W, \"b\": b} for i, (W, b) in enumerate(params)}\n",
    "    return flat\n",
    "\n",
    "def unflatten_params(flat_params):\n",
    "    unflat = [(flat_params[f\"layer_{i}\"][\"W\"], flat_params[f\"layer_{i}\"][\"b\"]) for i in range(len(params))]\n",
    "    return unflat\n",
    "\n",
    "opt_params = flatten_params(params)\n",
    "\n",
    "# Define the forward pass\n",
    "def forward(params, x):\n",
    "    for i, (W, b) in enumerate(params):\n",
    "        x = jnp.dot(x, W) + b\n",
    "        if i < len(params) - 1:  # Apply activation only for hidden layers\n",
    "            x = jax.nn.relu(x)\n",
    "    return x\n",
    "\n",
    "# Loss function (cross-entropy)\n",
    "def loss_fn(params, x, y):\n",
    "    logits = forward(params, x)\n",
    "    loss = -jnp.mean(jnp.sum(y * jax.nn.log_softmax(logits), axis=1))\n",
    "    return loss\n",
    "\n",
    "# Compute accuracy\n",
    "def accuracy_fn(params, x, y):\n",
    "    logits = forward(params, x)\n",
    "    predictions = jnp.argmax(logits, axis=1)\n",
    "    return jnp.mean(predictions == jnp.argmax(y, axis=1))\n",
    "\n",
    "# Optax Adam optimizer\n",
    "optimizer = optax.adam(lr)\n",
    "opt_state = optimizer.init(opt_params)\n",
    "\n",
    "# Gradient update function\n",
    "@jax.jit\n",
    "def update_fn(opt_params, opt_state, x, y):\n",
    "    def loss_closure(flat_params):\n",
    "        unflat = unflatten_params(flat_params)\n",
    "        return loss_fn(unflat, x, y)\n",
    "    \n",
    "    grads = jax.grad(loss_closure)(opt_params)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    new_params = optax.apply_updates(opt_params, updates)\n",
    "    return new_params, opt_state\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Shuffle data\n",
    "    perm = np.random.permutation(total_samples)\n",
    "    X_train_shuffled = X_train[perm]\n",
    "    y_train_onehot_shuffled = y_train_onehot[perm]\n",
    "\n",
    "    # Process each batch\n",
    "    for i in range(0, total_samples, batch_size):\n",
    "        X_batch = X_train_shuffled[i:i+batch_size]\n",
    "        y_batch = y_train_onehot_shuffled[i:i+batch_size]\n",
    "\n",
    "        opt_params, opt_state = update_fn(opt_params, opt_state, X_batch, y_batch)\n",
    "\n",
    "    # Compute loss and accuracy on the full training set\n",
    "    params = unflatten_params(opt_params)\n",
    "    train_loss = loss_fn(params, X_train, y_train_onehot)\n",
    "    train_acc = accuracy_fn(params, X_train, y_train_onehot)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}\")\n",
    "    if train_loss < 0.00001:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
