# LEARN BY BUILDING: Practicing ML Experiments in Jax

this is my series on doing ML experiments in jax (forward pass from scratch, automated backwards pass) to get faster/better at ML

my goal is to implement my own ML experiments. currently I am too slow/inefficient at implementing ML experiments

in this repo I train my skills in ML by practicing implementing experiments in jax, and optimizing them

jax is basically numpy but it can do autograd. this way I can focus on implementing networks without having to implement backprop by hand

I am doing this in a community on X called ["LEARN BY BUILDING"](https://x.com/i/communities/1860178670687818191) where we build projects as a way to learn tech stuff: programming, robotics, etc. If you have something you want to learn, join, come up with a project, and post whenever you make progress!

![alt text](res/lbb.png)


# projects so far
Train an MLP on MNIST

[Train a CNN on MNIST](https://x.com/dnbt777/status/1861678239602913395)
  - custom CNN with skip connections on MNIST

![alt text](res/cnn_post.png)

[Train an RNN/LSTM on my x posts](FINISHED/LSTM/LSTM.md)

![alt text](res/dann.png)

