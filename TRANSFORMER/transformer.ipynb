{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "experiment: first, train it on my posts\n",
    "make a language one first\n",
    "\n",
    "then.. hmm, not sure?\n",
    "\n",
    "maybe make a small one that can play a game at super low res? and RL it?\n",
    "\n",
    "have one that determines reward/punishment and one that decides actions?\n",
    "not sure lol but i want to win at panda bomber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrand\n",
    "import optax\n",
    "import functools # for partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lmaoooo [64 45 35  0  0  0  0] lmaoooo\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"../data/shakespeare.txt\"\n",
    "with open(dataset_path, 'r') as f:\n",
    "  dataset_chars = f.read()\n",
    "\n",
    "\n",
    "vocab = list(set(dataset_chars))\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "\n",
    "\n",
    "token_to_char_dict = dict(enumerate(vocab))\n",
    "char_to_token_dict = (dict([(b, a) for a, b in token_to_char_dict.items()]))\n",
    "\n",
    "encode = lambda word: jnp.array([char_to_token_dict[c] for c in word])\n",
    "decode = lambda tokens: \"\".join([token_to_char_dict[t] for t in tokens.tolist()])\n",
    "\n",
    "test_word = \"lmaoooo\"\n",
    "print(test_word, encode(test_word), decode(encode(test_word)))\n",
    "\n",
    "\n",
    "dataset = encode(dataset_chars)\n",
    "split = 0.9\n",
    "dataset_token_count = len(dataset)\n",
    "split_idx = int(dataset_token_count*0.9)\n",
    "\n",
    "train_data = dataset[:split_idx]\n",
    "test_data = dataset[split_idx:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model_params(key, attention_blocks, model_dim, kq_dim, forward_mlp_hidden_layers, embedding_table_hidden_layers, vocab_size, output_mlp_hidden_layers):\n",
    "  # inits model params\n",
    "  # function body logic:\n",
    "  #   generate params for the main transformer blocks\n",
    "  #   the embed table\n",
    "  #   and the final output MLP\n",
    "\n",
    "  key_types = 3 # (+ 3) + len(embedding_table_hidden_layers)*2)*100\n",
    "  keys = jrand.split(key, key_types)\n",
    "  # weight initialization functions\n",
    "  # he for sigmoid, xavier for tanh\n",
    "  he = lambda rkey, shape : jrand.normal(rkey, shape) * jnp.sqrt(2.0 / shape[0])\n",
    "  xavier = lambda rkey, shape : jrand.normal(rkey, shape) * jnp.sqrt(2.0 / (shape[0] + shape[1]))\n",
    "\n",
    "  # mlp takes an input embedding and outputs an embedding.\n",
    "  mlp_all_layer_sizes = jax.lax.concatenate([\n",
    "    jnp.array([model_dim]),\n",
    "    jnp.array(forward_mlp_hidden_layers),\n",
    "    jnp.array([model_dim])],\n",
    "    0\n",
    "  )\n",
    "  mlp_all_layer_shapes = [(a, b) for a, b in zip(mlp_all_layer_sizes, mlp_all_layer_sizes[1:])]\n",
    "\n",
    "  d_q = kq_dim\n",
    "  d_k = d_q\n",
    "  d_v = kq_dim # for now\n",
    "\n",
    "  kqv_keys = jrand.split(keys[0], attention_blocks*(len(forward_mlp_hidden_layers)*2))\n",
    "  model_params = [\n",
    "    {\n",
    "      \"attention\" : {\n",
    "        \"Wq\" : xavier(kqv_keys[i + 0], (model_dim, d_q)), # B, T, C => B, T, q\n",
    "        \"Wk\" : xavier(kqv_keys[i + 1], (model_dim, d_k)), # B, T, C => B, T, k\n",
    "        \"Wv\" : xavier(kqv_keys[i + 2], (model_dim, d_v)), # B, T, C => B, T, V.        B, T, T, @ B, T, V => B, T, V\n",
    "        \"Wout\" : xavier(kqv_keys[i + 2], (d_v, model_dim)), # B, T, V => B, T, C\n",
    "      },\n",
    "      \"forward\" : [\n",
    "        {\n",
    "          \"W\" : xavier(kqv_keys[i + layer], shape),\n",
    "          \"b\" : he(kqv_keys[i + layer + 1], (shape[1],)),\n",
    "        }\n",
    "        for layer, shape in enumerate(mlp_all_layer_shapes)\n",
    "      ],\n",
    "    }\n",
    "    for i in range(attention_blocks)\n",
    "  ]\n",
    "\n",
    "  # embed table params\n",
    "  embed_table_keys = jrand.split(keys[1], 2*len(embedding_table_hidden_layers))\n",
    "  embed_table_all_layer_sizes = jax.lax.concatenate([\n",
    "    jnp.array([vocab_size]),\n",
    "    jnp.array(embedding_table_hidden_layers),\n",
    "    jnp.array([model_dim])], 0)\n",
    "  embed_table_all_layer_shapes = [(a, b) for a, b in zip(embed_table_all_layer_sizes, embed_table_all_layer_sizes[1:])]\n",
    "  embedding_table_params = [\n",
    "        {\n",
    "          \"W\" : xavier(embed_table_keys[layer + 0], shape),\n",
    "          \"b\" : he(embed_table_keys[layer + 1], (shape[1],)),\n",
    "        }\n",
    "        for layer, shape in enumerate(embed_table_all_layer_shapes)\n",
    "  ]\n",
    "\n",
    "  model_params[0].update({\n",
    "    \"embedding_table_params\" : embedding_table_params\n",
    "  })\n",
    "\n",
    "  output_mlp_all_layer_sizes = jax.lax.concatenate([\n",
    "    jnp.array([model_dim]),\n",
    "    jnp.array(output_mlp_hidden_layers),\n",
    "    jnp.array([vocab_size])\n",
    "  ], 0)\n",
    "\n",
    "  # output MLP params. this takes the contextual embeddings and turns them into logits\n",
    "  output_mlp_keys = jrand.split(keys[2], 2*len(output_mlp_hidden_layers))\n",
    "  output_mlp_all_layer_shapes = [(a, b) for a, b in zip(output_mlp_all_layer_sizes, output_mlp_all_layer_sizes[1:])]\n",
    "  output_mlp_params = [\n",
    "    {\n",
    "      \"W\" : xavier(output_mlp_keys[layer + 0], shape),\n",
    "      \"b\" : he(output_mlp_keys[layer + 1], (shape[1],))\n",
    "    }\n",
    "    for layer, shape in enumerate(output_mlp_all_layer_shapes)\n",
    "  ]\n",
    "  model_params[-1].update({\n",
    "    \"output_mlp_params\" : output_mlp_params\n",
    "  })\n",
    "\n",
    "  return model_params\n",
    "\n",
    "\n",
    "\n",
    "# for both the mlp in attention blocks and the final output mlp.\n",
    "# in fact... i could probably use this for the embed table too. lmao\n",
    "@jax.jit\n",
    "def mlp_forward(mlp_params, x_input):\n",
    "  #linear = lambda x, params: (lambda x, W, b: x @ W + b)(x, params[\"W\"], params[\"b\"])\n",
    "\n",
    "  # doesnt work if leading axis sizes are different for some reason :(\n",
    "  #return jax.lax.scan(linear, contextual_embeddings, attention_block_params[\"forward\"])\n",
    "\n",
    "  x = x_input\n",
    "  for layer_params in mlp_params:\n",
    "    x = jax.nn.tanh(x @ layer_params[\"W\"] + layer_params[\"b\"]) # tanh : -1, 1\n",
    "  \n",
    "  return x\n",
    "\n",
    "\n",
    "@functools.partial(jax.jit, static_argnames=[\"vocab_size\"])\n",
    "def embed_tokens(embedding_table_params, xBT, vocab_size=vocab_size):\n",
    "  xBTC = jax.nn.one_hot(xBT, num_classes=vocab_size)\n",
    "  return mlp_forward(embedding_table_params, xBTC)\n",
    "\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def attention(Wq, Wk, Wv, Wout, d_k, xBTC):\n",
    "  Q = xBTC @ Wq # (B, T, C) @ (C, kq_dim) => (B, T, kq_dim)\n",
    "  K = xBTC @ Wk # (B, T, C) @ (C, kq_dim) => (B, T, kq_dim)\n",
    "  V = xBTC @ Wv # (B, T, C) @ (C, d_v) => (B, T, d_v)\n",
    "  attention_table = jax.nn.softmax((Q @ jnp.transpose(K, (0, 2, 1)))/d_k) # (B, T, kq_dim) @ (B, kq_dim, T) => (B, T, T)\n",
    "\n",
    "  Z = attention_table @ V  #  (B, T, T) @ (B, T, d_v) => (B, T, d_v)\n",
    "  contextual_embeddings = Z @ Wout # (B, T, d_v) @ (d_v, C) => (B, T, C)\n",
    "\n",
    "  return contextual_embeddings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### forward\n",
    "@jax.jit\n",
    "def forward(model_params, xBTC, d_k):\n",
    "  for attention_block in range(len(model_params)):\n",
    "    ## attention\n",
    "    contextual_embeddings = attention(\n",
    "      model_params[attention_block][\"attention\"][\"Wq\"],\n",
    "      model_params[attention_block][\"attention\"][\"Wk\"],\n",
    "      model_params[attention_block][\"attention\"][\"Wv\"],\n",
    "      model_params[attention_block][\"attention\"][\"Wout\"],\n",
    "      d_k,\n",
    "      xBTC\n",
    "    ) # B, T, C\n",
    "\n",
    "    # skip connection or whatever\n",
    "    xBTC = xBTC + mlp_forward(model_params[attention_block][\"forward\"], contextual_embeddings)\n",
    "\n",
    "  # finally, do something with the output\n",
    "  # doesnt matter what. predict the next token. take the next action. lol its whatever.\n",
    "  # for now just do next token prediction. implement a normal transformer\n",
    "  xBTC = mlp_forward(model_params[-1][\"output_mlp_params\"], xBTC)\n",
    "\n",
    "  return xBTC\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def inference(key, model_params, xBT, d_k, temperature=0.5):\n",
    "  embedding_table_params = model_params[0][\"embedding_table_params\"]\n",
    "  xBTC = embed_tokens(embedding_table_params, xBT)\n",
    "  yBTC = forward(model_params, xBTC, d_k)\n",
    "  next_token_logits = yBTC[:, -1, :] # the last T in (B, 1, C)\n",
    "  #next_token_probs = jax.nn.softmax(next_token_logits, axis=-1) # (B, C)\n",
    "  # argmax for display\n",
    "  probs = jax.nn.softmax(next_token_logits / (0.01 + temperature), axis=-1)\n",
    "  a = jnp.tile(jnp.arange(probs.shape[-1]), (probs.shape[0], 1))\n",
    "  print(a.shape, probs.shape)\n",
    "  return jrand.choice(key, a, p=probs, axis=-1)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def loss_func(model_params, xBT, yB, d_k):\n",
    "  embedding_table_params = model_params[0][\"embedding_table_params\"]\n",
    "  xBTC = embed_tokens(embedding_table_params, xBT)\n",
    "  yBTC = forward(model_params, xBTC, d_k)\n",
    "  next_token_logits = yBTC[:, -1, :] # the last T in (B, T, C)\n",
    "  # honestly this is stupid!!! C is a list of attributes of a token, 'logits' is the wrong datatype, even if theyre both represented as float\n",
    "  # fuck it just do baseline for now\n",
    "  next_token_probs = jax.nn.softmax(next_token_logits, axis=-1) # (B, C)\n",
    "  true_token_probs = jax.nn.one_hot(yB, next_token_probs.shape[-1], axis=-1) # (B, C)\n",
    "  batch_crossentropy = -true_token_probs * jax.nn.log_softmax(next_token_probs)\n",
    "  return jnp.mean(batch_crossentropy)\n",
    "\n",
    "\n",
    "# static args optimizer\n",
    "@functools.partial(jax.jit, static_argnames=[\"optimizer\"])\n",
    "def train_step(model_params, xBT, yB, d_k, opt_state, optimizer):\n",
    "  loss, grads = jax.value_and_grad(loss_func)(model_params, xBT, yB, d_k)\n",
    "  param_updates, updated_opt_state = optimizer.update(grads, opt_state, model_params)\n",
    "  updated_model_params = optax.apply_updates(model_params, param_updates)\n",
    "  return updated_model_params, updated_opt_state, loss, grads\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 65) (100, 65)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "p must be None or match the shape of a",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 51\u001b[0m\n\u001b[1;32m     49\u001b[0m yB \u001b[38;5;241m=\u001b[39m test_tokens[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;66;03m# lol ez\u001b[39;00m\n\u001b[1;32m     50\u001b[0m inference_key \u001b[38;5;241m=\u001b[39m jrand\u001b[38;5;241m.\u001b[39mPRNGKey(epoch \u001b[38;5;241m*\u001b[39m step \u001b[38;5;241m+\u001b[39m step)\n\u001b[0;32m---> 51\u001b[0m yhat \u001b[38;5;241m=\u001b[39m \u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43minference_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxBT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_k\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m model_params, opt_state, loss, grads \u001b[38;5;241m=\u001b[39m train_step(model_params, xBT, yB, d_k, opt_state, optimizer)\n\u001b[1;32m     54\u001b[0m in_chars \u001b[38;5;241m=\u001b[39m decode(xBT[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m↵\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "    \u001b[0;31m[... skipping hidden 11 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[95], line 166\u001b[0m, in \u001b[0;36minference\u001b[0;34m(key, model_params, xBT, d_k, temperature)\u001b[0m\n\u001b[1;32m    164\u001b[0m a \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mtile(jnp\u001b[38;5;241m.\u001b[39marange(probs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]), (probs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28mprint\u001b[39m(a\u001b[38;5;241m.\u001b[39mshape, probs\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjrand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ai_gym/.venv/lib/python3.10/site-packages/jax/_src/random.py:656\u001b[0m, in \u001b[0;36mchoice\u001b[0;34m(key, a, shape, replace, p, axis)\u001b[0m\n\u001b[1;32m    654\u001b[0m p_arr, \u001b[38;5;241m=\u001b[39m promote_dtypes_inexact(p)\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p_arr\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m (n_inputs,):\n\u001b[0;32m--> 656\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp must be None or match the shape of a\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m replace:\n\u001b[1;32m    658\u001b[0m   p_cuml \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mcumsum(p_arr)\n",
      "\u001b[0;31mValueError\u001b[0m: p must be None or match the shape of a"
     ]
    }
   ],
   "source": [
    "# model params\n",
    "attention_blocks = 2\n",
    "attention_heads = 8\n",
    "model_dim = 512\n",
    "kq_dim = 1024\n",
    "d_k = model_dim // attention_heads\n",
    "\n",
    "forward_mlp_hidden_layers = [\n",
    "  128,\n",
    "  128,\n",
    "  128,\n",
    "]\n",
    "\n",
    "output_mlp_hidden_layers = [\n",
    "  128,\n",
    "  128,\n",
    "  128,\n",
    "]\n",
    "\n",
    "embedding_table_hidden_layers = [\n",
    "  128,\n",
    "  128,\n",
    "  128\n",
    "]\n",
    "\n",
    "\n",
    "# set up training\n",
    "key = jrand.PRNGKey(112367)\n",
    "model_params = init_model_params(key, attention_blocks, model_dim, kq_dim, forward_mlp_hidden_layers, embedding_table_hidden_layers, vocab_size, output_mlp_hidden_layers)\n",
    "\n",
    "lr = 3e-4 # karpathy style\n",
    "optimizer = optax.adamw(learning_rate=lr)\n",
    "opt_state = optimizer.init(model_params)\n",
    "\n",
    "\n",
    "epochs = 1000\n",
    "train_batch_size = 100\n",
    "val_batch_size = 100\n",
    "max_sequence_length = 29 + 1 # xlen + ylen\n",
    "\n",
    "tokens_per_step = train_batch_size*max_sequence_length\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  steps = len(train_data) // (tokens_per_step) # idk calculate train_dataset_size // batch_size\n",
    "  for step in range(steps):\n",
    "    test_tokens = train_data[step*tokens_per_step:(step+1)*tokens_per_step].reshape(-1, max_sequence_length) # (B, T) where T = max seq len\n",
    "    xBT = test_tokens[:, :-1] # get all but last token in each sequence\n",
    "    # i need to turn this into every preceding subsequence. i.e. \"abcd\" => (xss, ys) => ([a, ab, abc], [b, c, d])\n",
    "    yB = test_tokens[:, -1] # lol ez\n",
    "    inference_key = jrand.PRNGKey(epoch * step + step)\n",
    "    yhat = inference(inference_key, model_params, xBT, d_k)\n",
    "    model_params, opt_state, loss, grads = train_step(model_params, xBT, yB, d_k, opt_state, optimizer)\n",
    "\n",
    "    in_chars = decode(xBT[0]).replace('\\n', '↵')\n",
    "    target_char = decode(jnp.array([yB[0]]))\n",
    "    pred_char = decode(jnp.array([yhat[0]]))\n",
    "\n",
    "    print(f\"{epoch}, {step}, {loss}, '{in_chars}' => '{pred_char}' =?> '{target_char}'\")\n",
    "\n",
    "\n",
    "\n",
    "# todo masking and multiple heads/concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee"
     ]
    }
   ],
   "source": [
    "def get_completion(prompt):\n",
    "  # this is LSTM style, not true transformer style.\n",
    "  xBT = encode(prompt)[None, :] # fake batch\n",
    "  yhat = inference(model_params, xBT, d_k) # will be messed up bc argmax instead of choosing probs\n",
    "  return decode(yhat)\n",
    "\n",
    "prompt = \"First Citizen:\\nBefore we proc\"\n",
    "print(prompt, end='')\n",
    "for i in range(100):\n",
    "  completion = get_completion(prompt)\n",
    "  print(completion, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 29) (100,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'attention': {'Wk': Array(4.0487752e-08, dtype=float32),\n",
       "   'Wout': Array(5.719531e-08, dtype=float32),\n",
       "   'Wq': Array(3.7466364e-08, dtype=float32),\n",
       "   'Wv': Array(5.1328307e-08, dtype=float32)},\n",
       "  'embedding_table_params': [{'W': Array(3.5487554e-07, dtype=float32),\n",
       "    'b': Array(8.610195e-08, dtype=float32)},\n",
       "   {'W': Array(2.4888416e-07, dtype=float32),\n",
       "    'b': Array(5.315047e-08, dtype=float32)},\n",
       "   {'W': Array(1.6377082e-07, dtype=float32),\n",
       "    'b': Array(3.5857084e-08, dtype=float32)},\n",
       "   {'W': Array(1.8392343e-07, dtype=float32),\n",
       "    'b': Array(3.6155512e-08, dtype=float32)}],\n",
       "  'forward': [{'W': Array(9.5017214e-08, dtype=float32),\n",
       "    'b': Array(1.220359e-08, dtype=float32)},\n",
       "   {'W': Array(1.4267002e-07, dtype=float32),\n",
       "    'b': Array(1.6234225e-08, dtype=float32)},\n",
       "   {'W': Array(1.5232071e-07, dtype=float32),\n",
       "    'b': Array(1.7687563e-08, dtype=float32)},\n",
       "   {'W': Array(2.2196433e-07, dtype=float32),\n",
       "    'b': Array(2.3666862e-08, dtype=float32)}]},\n",
       " {'attention': {'Wk': Array(1.9996467e-08, dtype=float32),\n",
       "   'Wout': Array(5.549425e-08, dtype=float32),\n",
       "   'Wq': Array(2.1245452e-08, dtype=float32),\n",
       "   'Wv': Array(4.6657128e-08, dtype=float32)},\n",
       "  'forward': [{'W': Array(1.0188071e-07, dtype=float32),\n",
       "    'b': Array(1.8104334e-09, dtype=float32)},\n",
       "   {'W': Array(2.5394039e-07, dtype=float32),\n",
       "    'b': Array(2.0069026e-08, dtype=float32)},\n",
       "   {'W': Array(1.839063e-07, dtype=float32),\n",
       "    'b': Array(1.8025078e-08, dtype=float32)},\n",
       "   {'W': Array(2.3831015e-07, dtype=float32),\n",
       "    'b': Array(2.3979835e-08, dtype=float32)}],\n",
       "  'output_mlp_params': [{'W': Array(4.7059456e-07, dtype=float32),\n",
       "    'b': Array(2.1653593e-08, dtype=float32)},\n",
       "   {'W': Array(8.2223545e-07, dtype=float32),\n",
       "    'b': Array(5.5455928e-08, dtype=float32)},\n",
       "   {'W': Array(1.2152823e-06, dtype=float32),\n",
       "    'b': Array(1.00713535e-07, dtype=float32)},\n",
       "   {'W': Array(3.241336e-06, dtype=float32),\n",
       "    'b': Array(3.3167117e-07, dtype=float32)}]}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(xBT.shape, yB.shape)\n",
    "jax.tree_util.tree_map(jnp.linalg.norm, grads)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
