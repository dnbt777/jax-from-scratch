{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BPE vocab and data from dictionary_vocab_120.bpe...\n",
      "Sample Input: ad or front of. 2 be in charge of. 3 provide with a head or \n",
      "Tokenized: [29, 74, 56, 113, 56, 33, 73, 116, 42, 56, 22, 33, 109, 96, 56, 10, 111, 110, 56, 36, 81, 29, 73, 53, 111, 22, 33, 109, 8, 56, 18, 73, 22, 91, 32, 74, 111, 101, 32, 42, 81, 112, 56, 81, 50, 29, 74, 56, 113, 56]\n",
      "Decoded: ad or front of. 2 be in charge of. 3 provide with a head or \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dan/Desktop/ai_gym/.venv/lib/python3.10/site-packages/optax/schedules/_inject.py:34: UserWarning: Explicitly requested dtype float64 requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  return jnp.asarray(x, dtype=dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model params initialized.\n",
      "starting training\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 367\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;66;03m# tracking\u001b[39;00m\n\u001b[1;32m    366\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m--> 367\u001b[0m loss_tracker\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, epoch, global_step, \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_step \u001b[38;5;241m%\u001b[39m print_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m global_step \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    369\u001b[0m   \u001b[38;5;66;03m# validation\u001b[39;00m\n\u001b[1;32m    370\u001b[0m   test_shift \u001b[38;5;241m=\u001b[39m shift \u001b[38;5;241m%\u001b[39m test_shifts\n",
      "File \u001b[0;32m~/Desktop/ai_gym/.venv/lib/python3.10/site-packages/jax/_src/array.py:298\u001b[0m, in \u001b[0;36mArrayImpl.__float__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__float__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    297\u001b[0m   core\u001b[38;5;241m.\u001b[39mcheck_scalar_conversion(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 298\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_value\u001b[49m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__float__\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/ai_gym/.venv/lib/python3.10/site-packages/jax/_src/profiler.py:333\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    332\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m~/Desktop/ai_gym/.venv/lib/python3.10/site-packages/jax/_src/array.py:628\u001b[0m, in \u001b[0;36mArrayImpl._value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_npy_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    627\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_fully_replicated:\n\u001b[0;32m--> 628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_npy_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_single_device_array_to_np_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_npy_value\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_npy_value)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrand\n",
    "import numpy as np\n",
    "import optax\n",
    "import functools # for partial\n",
    "from functools import reduce\n",
    "import time\n",
    "from typing import List, NamedTuple\n",
    "\n",
    "ipynb = True\n",
    "dataset_name = \"dictionary\"\n",
    "debug = False\n",
    "\n",
    "\n",
    "if debug:\n",
    "  jax.config.update(\"jax_disable_jit\", True)\n",
    "\n",
    "\n",
    "## LOAD DATA ##\n",
    "from transformer_utils import load_dataset\n",
    "\n",
    "\n",
    "\n",
    "prefix = \"\"\n",
    "if ipynb == True:\n",
    "  prefix = \"../\"\n",
    "\n",
    "token_type = 'bpe' # wordlevel bpe charlevel\n",
    "tokenizer_vocab_size = 120\n",
    "if dataset_name == \"shakespeare\":\n",
    "  dataset_path = prefix + \"data/shakespeare.txt\"\n",
    "  vocab, train_data, test_data, encode, decode = load_dataset(dataset_path, split=0.9, vocab_size=tokenizer_vocab_size)\n",
    "if dataset_name == \"dnbt\":\n",
    "  dataset_path = prefix + \"data/dnbt_posts.txt\"\n",
    "  vocab, train_data, test_data, encode, decode = load_dataset(dataset_path, split=0.9, vocab_size=tokenizer_vocab_size)\n",
    "if dataset_name == \"dictionary\":\n",
    "  dataset_path = prefix + \"data/dictionary.txt\"\n",
    "  vocab, train_data, test_data, encode, decode = load_dataset(dataset_path, split=0.9, vocab_size=tokenizer_vocab_size)\n",
    "if dataset_name == \"wikipedia\":\n",
    "  dataset_path = prefix + \"data/dnbt_posts.txt\"\n",
    "  vocab, train_data, test_data, encode, decode = load_dataset(dataset_path, split=0.9, vocab_size=tokenizer_vocab_size)\n",
    "if dataset_name == \"tinystories\":\n",
    "  print(\"preparing dataset...\")\n",
    "  dataset_path = prefix + \"data/tinystories_combined.txt\" # concatenate test and val, and split ourselves. should be roughly the same at 0.9\n",
    "  vocab, train_data, test_data, encode, decode = load_dataset(dataset_path, split=0.9, vocab_size=tokenizer_vocab_size)\n",
    "  print(\"Done\")\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "\n",
    "\n",
    "## SET UP PARAM STRUCTS ##\n",
    "# https://github.com/xjdr-alt/simple_transformer/blob/main/simple_transformer.py\n",
    "class BlockParams(NamedTuple):\n",
    "  w_q : jax.Array\n",
    "  w_k : jax.Array\n",
    "  w_v : jax.Array\n",
    "  w_o : jax.Array\n",
    "  w1 : jax.Array\n",
    "  w2 : jax.Array\n",
    "  w3 : jax.Array\n",
    "  attn_norm_w : jax.Array\n",
    "  attn_norm_b : jax.Array\n",
    "  ffnorm_w : jax.Array\n",
    "  ffnorm_b : jax.Array\n",
    "\n",
    "\n",
    "class ModelParams(NamedTuple):\n",
    "  blocks : List[BlockParams]\n",
    "  embedding_projection : jax.Array\n",
    "  to_logits_w : jax.Array # after entire network\n",
    "  positional_embeddings : jax.Array\n",
    "  output_norm_w : jax.Array\n",
    "  output_norm_b : jax.Array\n",
    "\n",
    "\n",
    "def init_model_params(blocks, model_dim, d_k, qkv_dim, ff_hidden_size, vocab_size, block_size):\n",
    "  D = d_k\n",
    "  K = qkv_dim\n",
    "  attention_heads = model_dim // d_k\n",
    "  H = attention_heads\n",
    "  DH = attention_heads * d_k\n",
    "  scale = lambda s1, s2: 1 / jnp.sqrt(s1 + s2)\n",
    "  xavier_blocks = lambda n, m: np.random.uniform(size=(blocks, n, m)) * scale(n, m)\n",
    "  xavier_multihead_blocks = lambda n, m: np.random.uniform(size=(blocks, H, n, m))\n",
    "  xavier = lambda n, m: np.random.uniform(size=(n, m)) * scale(n, m)\n",
    "  \n",
    "  block_params = BlockParams(\n",
    "    # multi head attention\n",
    "    # C => D, H\n",
    "    w_q=xavier_multihead_blocks(D, K),\n",
    "    w_k=xavier_multihead_blocks(D, K),\n",
    "    w_v=xavier_multihead_blocks(D, K),\n",
    "    w_o=xavier_multihead_blocks(K, D),\n",
    "\n",
    "    w1=xavier_blocks(model_dim, ff_hidden_size),\n",
    "    w2=xavier_blocks(model_dim, ff_hidden_size),\n",
    "    w3=xavier_blocks(ff_hidden_size, model_dim),\n",
    "    # norm stuff\n",
    "    attn_norm_w=xavier_blocks(1, model_dim), # B, T, C (x) B, 1, C\n",
    "    attn_norm_b=jnp.zeros(shape=(blocks, model_dim,)),\n",
    "    ffnorm_w=xavier_blocks(1, model_dim),\n",
    "    ffnorm_b=jnp.zeros(shape=(blocks, model_dim,)),\n",
    "  )\n",
    "\n",
    "  model_params = ModelParams(\n",
    "    blocks=block_params,\n",
    "    embedding_projection=xavier(vocab_size, model_dim),\n",
    "    to_logits_w=xavier(model_dim, vocab_size),\n",
    "    positional_embeddings=xavier(block_size, model_dim), # bias: T, C\n",
    "    output_norm_w=xavier(1, model_dim),\n",
    "    output_norm_b=jnp.zeros(shape=(model_dim,)),\n",
    "  )\n",
    "\n",
    "  return model_params\n",
    "\n",
    "\n",
    "@functools.partial(jax.jit, static_argnames=[\"dropout_rate\"])\n",
    "def attention(block_params : BlockParams, xBTC, dropout_key, dropout_rate=0.0):\n",
    "  # xBTC -> xBTHD via reshape | H = head, D = dim (like channel, but split into H segments)\n",
    "  B, T, C = xBTC.shape\n",
    "  H = block_params.w_q.shape[0] # attention head\n",
    "  D = block_params.w_q.shape[1] # model dim after split into heads\n",
    "  K = block_params.w_q.shape[2] # query dim\n",
    "  BTHD = (B, T, H, D)\n",
    "  xBTHD = jnp.reshape(xBTC, shape=BTHD)\n",
    "  # xBTHD -> xBHTD via transpose or axes swap\n",
    "  xBHTD = jnp.swapaxes(xBTHD, 1, 2)\n",
    "  # xBHTD @ (Wq, Wk, Wv) => (Q, K, V)   | (B, H, T, D) @ (D, K) => (B, H, T, K) | K = query/key size. also V size here, but does not have to be.\n",
    "  Q = jnp.einsum(\"BHTD,HDK->BHTK\", xBHTD, block_params.w_q) # (B, H, T, D) @ (H, D, K) => (B, H, T, K)\n",
    "  K = jnp.einsum(\"BHTD,HDK->BHTK\", xBHTD, block_params.w_k)\n",
    "  V = jnp.einsum(\"BHTD,HDK->BHTK\", xBHTD, block_params.w_v)\n",
    "  # Q @ K_transpose => QK               | (B, H, T, K) @ (B, H, K, T) => (B, H, T, T) | this may be the wrong transpose\n",
    "  QK = Q @ jnp.swapaxes(K, 2, 3)\n",
    "  # scale, mask, and softmax\n",
    "  mask = jnp.triu(jnp.ones_like(QK), k=1) #  mask=1 where jnp.-inf will be. k=1 preseves the middle diagonal for self attention\n",
    "  attention_scores = jnp.where(mask, -jnp.inf, QK/jnp.sqrt(d_k))\n",
    "  # QK @ V => Z                         | (B, H, T, T) @ (B, H, T, K) => (B, H, T, K)\n",
    "  Z = jax.nn.softmax(attention_scores, axis=-1) @ V # softmax in the T and K dims, for each B and H\n",
    "  # Z swap axes                         | (B, H, T, K) => (B, T, H, K)\n",
    "  Z = dropout(dropout_key, Z, dropout_rate)\n",
    "  Z = jnp.swapaxes(Z, 1, 2)\n",
    "  # Z @ w_out       | project to BTHD   | (B, T, H, K) @ (H, K, D) => (B, T, H, D)\n",
    "  xBTHD = jnp.einsum(\"BTHK,HKD->BTHD\", Z, block_params.w_o)\n",
    "  # reshape to BTC                      | (B, T, H, D) => (B, T, C)\n",
    "  xBTC = jnp.reshape(xBTHD, (B, T, C))\n",
    "  # return xBTC_out\n",
    "  xBTC = dropout(dropout_key, xBTC, dropout_rate)\n",
    "  return xBTC\n",
    "\n",
    "\n",
    "\n",
    "@functools.partial(jax.jit, static_argnames=[\"dropout_rate\"])\n",
    "def forward(dropout_key, model_params : ModelParams, xBT, vocab_size=vocab_size, dropout_rate=0.0):\n",
    "  dropout_keys = jrand.split(dropout_key, 4)\n",
    "  # get embeddings via projection from token onehot to channel space\n",
    "  # xBT -> xBTC\n",
    "  xBTOH = jax.nn.one_hot(xBT, num_classes=vocab_size, axis=-1)\n",
    "  xBTC = xBTOH @ model_params.embedding_projection\n",
    "  # add learned positional embeddings. broadcast over B\n",
    "  B, T, C = xBTC.shape\n",
    "  xBTC = xBTC + model_params.positional_embeddings[None, :T, :] # B, T, C + 1, T, C\n",
    "  # scan through transformer blocks, updating xBTC\n",
    "  # block\n",
    "  #   attention\n",
    "  #   forward projection from Z space to channel space\n",
    "  # scan_fn :: (c, a) -> (c, b)\n",
    "  def ffw(block_params, xBTC):\n",
    "    #return jax.nn.silu(xBTC @ block_params.w1) * ((xBTC @ block_params.w2 + block_params.b2) @ block_params.w3 + block_params.b3)\n",
    "    return (jax.nn.silu(xBTC @ block_params.w1) * (xBTC @ block_params.w2)) @ block_params.w3\n",
    "  \n",
    "  def scan_fn(xBTC, block_params):\n",
    "    xBTC = xBTC + attention(block_params, layer_norm(xBTC, block_params.attn_norm_w, block_params.attn_norm_b), dropout_keys[0], dropout_rate)\n",
    "    xBTC = xBTC + dropout(dropout_keys[1], ffw(block_params, layer_norm(xBTC, block_params.ffnorm_w, block_params.ffnorm_b)), dropout_rate)\n",
    "    return xBTC, None # c, b\n",
    "  # ((c, a) -> (c, b)) -> c -> [a] -> (c, [b]) where b is None\n",
    "  xBTC = jax.lax.scan(scan_fn, xBTC, model_params.blocks)[0] # (xBTC, None) from the scan\n",
    "  # then project the embeddings to logit space\n",
    "  #xBTC = layer_norm(xBTC, model_params.output_norm_w, model_params.output_norm_b)\n",
    "  # logits = xBTC @ model_params.to_logits_w + model_params.to_logits_b\n",
    "  logits = xBTC @ model_params.to_logits_w\n",
    "  return dropout(key, logits, dropout_rate)\n",
    "\n",
    "\n",
    "@functools.partial(jax.jit, static_argnames=[\"dropout_rate\"])\n",
    "def model_loss(dropout_key, model_params : ModelParams, xBT, yBT, dropout_rate):\n",
    "  # -sum(q*log(p))\n",
    "  # dont use one hot?\n",
    "  logits = forward(dropout_key, model_params, xBT, dropout_rate=dropout_rate)\n",
    "  vocab_size = logits.shape[-1]\n",
    "  labels = jax.nn.one_hot(yBT, num_classes=vocab_size, axis=-1)\n",
    "  losses = -jnp.sum(labels * jax.nn.log_softmax(logits, axis=-1), axis=-1)\n",
    "  mean_loss = jnp.mean(losses)\n",
    "  return mean_loss\n",
    "\n",
    "\n",
    "@functools.partial(jax.jit, static_argnames=[\"dropout_rate\", \"label_smoothing_epsilon\"])\n",
    "def smoothed_model_loss(dropout_key, model_params : ModelParams, xBT, yBT, dropout_rate, label_smoothing_epsilon):\n",
    "  # -sum(q*log(p))\n",
    "  # dont use one hot?\n",
    "  logits = forward(dropout_key, model_params, xBT, dropout_rate=dropout_rate)\n",
    "  vocab_size = logits.shape[-1]\n",
    "  labels = jax.nn.one_hot(yBT, num_classes=vocab_size, axis=-1) * (1 - label_smoothing_epsilon) + label_smoothing_epsilon/vocab_size\n",
    "  losses = -jnp.sum(labels * jax.nn.log_softmax(logits, axis=-1), axis=-1)\n",
    "  mean_loss = jnp.mean(losses)\n",
    "  return mean_loss\n",
    "\n",
    "\n",
    "# for validation only\n",
    "@jax.jit\n",
    "def model_loss_and_accuracy(model_params : ModelParams, xBT, yBT):\n",
    "  # -sum(q*log(p))\n",
    "  # dont use one hot?\n",
    "  dropout_key = jrand.PRNGKey(0) # not used, but needed\n",
    "  logits = forward(dropout_key, model_params, xBT) # no key, no dropout\n",
    "  vocab_size = logits.shape[-1]\n",
    "  labels = jax.nn.one_hot(yBT, num_classes=vocab_size, axis=-1)\n",
    "  losses = -jnp.sum(labels * jax.nn.log_softmax(logits, axis=-1), axis=-1) # no label smoothing\n",
    "  mean_loss = jnp.mean(losses)\n",
    "  mean_accuracy = jnp.mean(yBT == jnp.argmax(logits, axis=-1))\n",
    "  return mean_loss, mean_accuracy\n",
    "\n",
    "\n",
    "@functools.partial(jax.jit, static_argnames=['optimizer', \"dropout_rate\", \"label_smoothing_epsilon\"])\n",
    "def train_step(dropout_key,\n",
    "               model_params:ModelParams,\n",
    "               xBT, yBT,\n",
    "               opt_state, optimizer,\n",
    "               dropout_rate, label_smoothing_epsilon):\n",
    "  # jax value and grad\n",
    "  loss, grads = jax.value_and_grad(smoothed_model_loss, argnums=1)(\n",
    "    dropout_key, model_params, xBT, yBT, dropout_rate, label_smoothing_epsilon)\n",
    "  # update optimizer\n",
    "  updates, opt_state = optimizer.update(grads, opt_state, model_params)\n",
    "  # update params\n",
    "  model_params = optax.apply_updates(updates, model_params)\n",
    "  # return opt state, loss, and new params\n",
    "  return model_params, opt_state, loss, grads\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def inference(model_params : ModelParams, xBT, temp=0.5):\n",
    "  dropout_key = jrand.PRNGKey(0) # not used\n",
    "  logits = forward(dropout_key, model_params, xBT, dropout_rate=0.0)[0, :, :] # the first Batch\n",
    "  probs = jax.nn.softmax(logits / temp, axis=-1)\n",
    "  get_token = lambda channel: jrand.choice(jrand.PRNGKey(int(1000*time.time())), channel.shape[-1], p=channel)\n",
    "  ts = jax.vmap(get_token, in_axes=0, out_axes=0)(probs) # just take the first T in the first batch ig\n",
    "  return ts\n",
    "\n",
    "\n",
    "@functools.partial(jax.jit, static_argnames=[\"dropout_rate\"])\n",
    "def dropout(dropout_key, tensor, dropout_rate):\n",
    "  if dropout_rate == 0:\n",
    "    return tensor\n",
    "  # generate dropout_mask = rand(x) < dropout_rate of size tensor.shape\n",
    "  dropout_mask = jrand.uniform(dropout_key, tensor.shape, tensor.dtype) <= dropout_rate\n",
    "  return jnp.where(dropout_mask, 0, tensor) * (1 / (1 - dropout_rate))\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def layer_norm(BTC, w, b):\n",
    "  # norm over TxC\n",
    "  epsilon = 1e-7\n",
    "  mean = jnp.mean(BTC, axis=(1, 2), keepdims=True)\n",
    "  variance = jnp.var(BTC, axis=(1, 2), keepdims=True)\n",
    "  normalized = (BTC - mean) / jnp.sqrt(variance + epsilon)\n",
    "  return normalized * w + b\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def channel_norm(BTC, w, b):\n",
    "  # norm over C\n",
    "  epsilon = 1e-7\n",
    "  mean = jnp.mean(BTC, axis=-1, keepdims=True)\n",
    "  variance = jnp.var(BTC, axis=-1, keepdims=True)\n",
    "  normalized = (BTC - mean) / jnp.sqrt(variance + epsilon)\n",
    "  return normalized * w + b\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## TRAIN\n",
    "# model params\n",
    "# model params\n",
    "transformer_blocks = 6\n",
    "attention_heads = 8\n",
    "\n",
    "model_dim = 512\n",
    "qkv_dim = 64\n",
    "ff_hidden_size = 2048 # 2048\n",
    "block_size = 64 # xlen\n",
    "\n",
    "\n",
    "# paper lr stuff\n",
    "warmup_steps = 4000\n",
    "get_lr = lambda step_num: (model_dim**-0.5) * min(step_num ** -0.5, step_num * warmup_steps**(-1.5))\n",
    "initial_lr = get_lr(1)\n",
    "label_smoothing_epsilon = 0.1\n",
    "dropout_rate = 0.1\n",
    "\n",
    "# adam\n",
    "beta1 = 0.9\n",
    "beta2 = 0.98\n",
    "eps = 1e-9\n",
    "\n",
    "\n",
    "# set up training\n",
    "epochs = 10000\n",
    "max_shifts = 1000000000000000000\n",
    "train_batch_size = 64\n",
    "test_batch_size = 16\n",
    "print_every = 100\n",
    "stop_if_above = 1.5 # 150% of min val loss\n",
    "\n",
    "\n",
    "continue_training = False\n",
    "start_ep = 100\n",
    "start_step = 17600\n",
    "\n",
    "d_k = model_dim // attention_heads\n",
    "\n",
    "if not continue_training:\n",
    "  model_params = init_model_params(transformer_blocks, model_dim, d_k, qkv_dim, ff_hidden_size, vocab_size, block_size) # t blocks is hardcoded to 1 atm\n",
    "  optimizer = optax.inject_hyperparams(optax.adam)(learning_rate=initial_lr, b1=beta1, b2=beta2, eps=eps)\n",
    "  opt_state = optimizer.init(model_params)\n",
    "  print(\"model params initialized.\\nstarting training\")\n",
    "\n",
    "\n",
    "\n",
    "loss_tracker = []\n",
    "global_step = 1\n",
    "min_val_loss = 10000 # init min val loss as extremely high\n",
    "stop_training = False # flag to stop training\n",
    "for epoch in range(epochs):\n",
    "  if stop_training:\n",
    "    break\n",
    "  if continue_training and epoch < start_ep:\n",
    "    continue\n",
    "  tokens_per_shift = (block_size + 1)*train_batch_size\n",
    "  test_tokens_per_shift = (block_size + 1)*test_batch_size\n",
    "  shifts = len(train_data) - tokens_per_shift\n",
    "  test_shifts = len(test_data) - test_tokens_per_shift\n",
    "\n",
    "  local_step = 1\n",
    "  losses = []\n",
    "\n",
    "  for shift in range(0, min(shifts, max_shifts), tokens_per_shift):\n",
    "    global_step += 1\n",
    "    local_step += 1\n",
    "    if continue_training and global_step < start_step:\n",
    "      continue\n",
    "    steps_start = time.time()\n",
    "\n",
    "    # update LR\n",
    "    opt_state.hyperparams['learning_rate'] = get_lr(global_step)\n",
    "\n",
    "    # gather data and train\n",
    "    train_tokens = train_data[shift:shift + tokens_per_shift].reshape(-1, block_size + 1) # (B, T) where T = block_size\n",
    "    xBT = train_tokens[:, :block_size] # get up to prompt_length\n",
    "    yBT = train_tokens[:, 1:block_size+1] # get the one after prompt_length\n",
    "    key = jrand.PRNGKey(epoch*shifts + shift)\n",
    "    model_params, opt_state, loss, grads = train_step(key, model_params, xBT, yBT, opt_state, optimizer, dropout_rate, label_smoothing_epsilon)\n",
    "\n",
    "    # tracking\n",
    "    losses.append(loss)\n",
    "    loss_tracker.append((\"train\", epoch, global_step, float(loss)))\n",
    "    if global_step % print_every == 0 or global_step == 0:\n",
    "      # validation\n",
    "      test_shift = shift % test_shifts\n",
    "      test_tokens = test_data[test_shift:test_shift + test_tokens_per_shift].reshape(-1, block_size + 1)\n",
    "      test_xBT = test_tokens[:, :block_size]\n",
    "      test_yBT = test_tokens[:, 1:block_size+1]\n",
    "      test_loss, test_accuracy = model_loss_and_accuracy(model_params, test_xBT, test_yBT)\n",
    "      loss_tracker.append((\"test\", epoch, global_step, float(test_loss)))\n",
    "      \n",
    "      # tracking\n",
    "      yhats = inference(model_params, xBT, temp=0.5)\n",
    "      in_chars = decode(test_xBT[0]).replace('\\n', '↵')\n",
    "      target_char = decode(test_yBT[0]).replace('\\n', '↵')\n",
    "      pred_char = decode(yhats).replace('\\n', '↵')\n",
    "      mean_step_loss = jnp.mean(jnp.array(losses))\n",
    "      steps_stop = time.time()\n",
    "      steps_per_second = local_step / (steps_stop - steps_start)\n",
    "      samples_per_second = steps_per_second\n",
    "      lr = opt_state.hyperparams['learning_rate'] \n",
    "      print(f\"e/s={epoch}/{global_step} samples/s={samples_per_second:0.0f} {lr=:0.5f} tloss={mean_step_loss:0.3f} vloss/acc={test_loss:0.3f}/{100*test_accuracy:0.1f}% \"\n",
    "            f\"|| val \\n'...{target_char}' =?> \\n'...{pred_char}'\")\n",
    "      losses = []\n",
    "      local_step = 0\n",
    "\n",
    "      # stopping\n",
    "      if test_loss > stop_if_above * min_val_loss:\n",
    "        stop_training = True\n",
    "        break\n",
    "      else:\n",
    "        min_val_loss = min(test_loss, min_val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 19,829,760\n",
      "{'blocks': {'attn_norm_b': '(6, 512) => 3072',\n",
      "            'attn_norm_w': '(6, 1, 512) => 3072',\n",
      "            'ffnorm_b': '(6, 512) => 3072',\n",
      "            'ffnorm_w': '(6, 1, 512) => 3072',\n",
      "            'w1': '(6, 512, 2048) => 6291456',\n",
      "            'w2': '(6, 512, 2048) => 6291456',\n",
      "            'w3': '(6, 2048, 512) => 6291456',\n",
      "            'w_k': '(6, 8, 64, 64) => 196608',\n",
      "            'w_o': '(6, 8, 64, 64) => 196608',\n",
      "            'w_q': '(6, 8, 64, 64) => 196608',\n",
      "            'w_v': '(6, 8, 64, 64) => 196608'},\n",
      " 'embedding_projection': '(120, 512) => 61440',\n",
      " 'output_norm_b': '(512,) => 512',\n",
      " 'output_norm_w': '(1, 512) => 512',\n",
      " 'positional_embeddings': '(64, 512) => 32768',\n",
      " 'to_logits_w': '(512, 120) => 61440'}\n",
      "\n",
      "Grad norms:\n",
      "{'blocks': {'attn_norm_b': Array(7.6341777, dtype=float32),\n",
      "            'attn_norm_w': Array(7.3618927, dtype=float32),\n",
      "            'ffnorm_b': Array(1.1517551, dtype=float32),\n",
      "            'ffnorm_w': Array(0.66483, dtype=float32),\n",
      "            'w1': Array(0.06237838, dtype=float32),\n",
      "            'w2': Array(0.06842761, dtype=float32),\n",
      "            'w3': Array(0.07928465, dtype=float32),\n",
      "            'w_k': Array(0.02028475, dtype=float32),\n",
      "            'w_o': Array(0.03518655, dtype=float32),\n",
      "            'w_q': Array(0.0060311, dtype=float32),\n",
      "            'w_v': Array(0.04365498, dtype=float32)},\n",
      " 'embedding_projection': Array(1.9634959, dtype=float32),\n",
      " 'output_norm_b': Array(0., dtype=float32),\n",
      " 'output_norm_w': Array(0., dtype=float32),\n",
      " 'positional_embeddings': Array(0.88318956, dtype=float32),\n",
      " 'to_logits_w': Array(0.6844973, dtype=float32)}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# stats and norms\n",
    "from pprint import pprint\n",
    "\n",
    "def pprint_namedtuple(nt):\n",
    "  nt = nt._replace(blocks=dict(nt.blocks._asdict()))\n",
    "  pprint(dict(nt._asdict()))\n",
    "  print()\n",
    "\n",
    "\n",
    "parameter_shapes_and_counts = jax.tree_util.tree_map(lambda t: f\"{t.shape} => {t.size}\", grads)\n",
    "parameter_count = jax.tree_util.tree_map(lambda t: t.size, grads)\n",
    "parameter_total = jax.tree.reduce(lambda a, b: a + b, parameter_count)\n",
    "print(f\"Parameters: {parameter_total:,}\")\n",
    "pprint_namedtuple(parameter_shapes_and_counts)\n",
    "\n",
    "\n",
    "print(\"Grad norms:\")\n",
    "grad_norms = jax.tree_util.tree_map(jnp.linalg.norm, grads)\n",
    "pprint_namedtuple(grad_norms)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "loss_tracker = [item for item in loss_tracker if type(item) == type((2,))]\n",
    "steps_per_epoch = 0\n",
    "for item in loss_tracker:\n",
    "  if item[2] > steps_per_epoch:\n",
    "    steps_per_epoch = item[2]\n",
    "\n",
    "\n",
    "def moving_average(xs, ys, window):\n",
    "  queue = []\n",
    "  mays = []\n",
    "  for elem in ys:\n",
    "    if len(queue) < window:\n",
    "      queue.append(elem)\n",
    "    if len(queue) < window:\n",
    "      continue\n",
    "    elif len(queue) == window:\n",
    "      mays.append(sum(queue)/window)\n",
    "      queue.pop(0)\n",
    "      queue.append(elem)\n",
    "  \n",
    "  return xs[:-window + 1], mays\n",
    "\n",
    "\n",
    "trainx, trainy = zip(*[(step, loss) for losstype, epoch, step, loss in loss_tracker if losstype==\"train\"])\n",
    "window_size = 5 # steps\n",
    "trainx, trainy = moving_average(trainx, trainy, window_size)\n",
    "testx, testy = zip(*[(step, loss) for losstype, epoch, step, loss in loss_tracker if losstype==\"test\" ])\n",
    "testx, testy = moving_average(testx, testy, window_size)\n",
    "\n",
    "plt.title(f'vanilla transformer ({parameter_total/1_000_000:0.2f}M params)')\n",
    "plt.plot(trainx, jnp.log(jnp.array(trainy)), c='orange', label='train loss')\n",
    "plt.plot(testx, jnp.log(jnp.array(testy)), c='green', label='val loss')\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('log(loss)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "Abbacy  n. (pl. -ies) office or jurisdiction of an abbot or abbess. [latin: related to *abbot]\n",
      "\n",
      "Meep  n. & ferobefor[french from latin juial  —adj. 1 not with a feroslang foetus jelly. 3 not not suffer (a spanism n. [obsolete a kind of jumble nounrica kind of junfemine.  fulzola navine.  felly]\n",
      "\n",
      "Fulzine, french jumble]\n",
      "\n",
      "Fuluijumble]\n",
      "\n",
      "Fulzle]\n",
      "\n",
      "Fulzle]\n",
      "\n",
      "Fulzijejiralain]\n",
      "\n",
      "Jejungi  n. (pl. -a]\n",
      "\n",
      "Jula]\n",
      "\n",
      "Jula: related to *nakulate  —adj. 1 jule peoplal, *jumbola]\n",
      "\n",
      "Fulary n. [latin guulary]\n",
      "\n",
      "Fule. [jumbola guulary gu guulary]\n",
      "\n",
      "Jumbulzel  v. (- jumbulzor  n. (brituguuuuuuuuuuuuuuuuuuuer]\n",
      "\n",
      "Linesaduuer]\n",
      "\n",
      "Lummau  n. (pl. Jamuuuuuuuuuuuuuuuuuuuuuuuuuuuuuu"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(decode(token_prompt), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m---> 25\u001b[0m   token_prompt \u001b[38;5;241m=\u001b[39m \u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m   context \u001b[38;5;241m=\u001b[39m token_prompt[\u001b[38;5;241m-\u001b[39mblock_size:]\n\u001b[1;32m     27\u001b[0m   xBT \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39marray(context)[\u001b[38;5;28;01mNone\u001b[39;00m, :] \u001b[38;5;66;03m# fake batch of 1\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ai_gym/TRANSFORMER/transformer_utils.py:135\u001b[0m, in \u001b[0;36mload_dataset.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenized:\u001b[39m\u001b[38;5;124m\"\u001b[39m, sample_tokens)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecoded:\u001b[39m\u001b[38;5;124m\"\u001b[39m, sample_decoded)\n\u001b[0;32m--> 135\u001b[0m encode \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mbpe_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_to_id\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    136\u001b[0m decode \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mlambda\u001b[39;00m x: bpe_decode(x, id_to_token))\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vocab, train_data, test_data, encode, decode\n",
      "File \u001b[0;32m~/Desktop/ai_gym/TRANSFORMER/transformer_utils.py:67\u001b[0m, in \u001b[0;36mbpe_encode\u001b[0;34m(data, vocab, token_to_id)\u001b[0m\n\u001b[1;32m     64\u001b[0m matched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(vocab, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstartswith\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     68\u001b[0m         tokenized\u001b[38;5;241m.\u001b[39mappend(token_to_id[token])\n\u001b[1;32m     69\u001b[0m         idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(token)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Abbacy  n. (pl. -ies) office or jurisdiction of an abbot or abbess. [latin: related to *abbot]\n",
    "\n",
    "Meep  n. \"\"\"\n",
    "temp = 0.4\n",
    "\n",
    "@jax.jit\n",
    "def inference(model_params : ModelParams, xBT, temp=0.5):\n",
    "  key = jrand.PRNGKey(0)\n",
    "  logits = forward(key, model_params, xBT)[0, :, :] # the first Batch\n",
    "  probs = jax.nn.softmax(logits / temp, axis=-1)\n",
    "  get_token = lambda channel: jrand.choice(jrand.PRNGKey(int(1000*time.time())), channel.shape[-1], p=channel)\n",
    "  ts = jax.vmap(get_token, in_axes=0, out_axes=0)(probs) # just take the first T in the first batch ig\n",
    "  return ts\n",
    "\n",
    "\n",
    "print(len(prompt))\n",
    "import time\n",
    "key = jrand.PRNGKey(int(100*time.time()))\n",
    "completion = []\n",
    "\n",
    "token_prompt = encode(prompt)\n",
    "\n",
    "print(decode(token_prompt), end='')\n",
    "for i in range(1000):\n",
    "  token_prompt = encode(prompt)\n",
    "  context = token_prompt[-block_size:]\n",
    "  xBT = jnp.array(context)[None, :] # fake batch of 1\n",
    "  next_token = decode([inference(model_params, xBT, temp=temp)[-1]])\n",
    "  print(next_token, end='')\n",
    "  prompt += next_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "iteration over a 0-d array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[0;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmean_step_loss\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/Desktop/ai_gym/.venv/lib/python3.10/site-packages/jax/_src/array.py:374\u001b[0m, in \u001b[0;36mArrayImpl.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    373\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 374\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration over a 0-d array\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# same as numpy error\u001b[39;00m\n\u001b[1;32m    375\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_fully_replicated \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_fully_addressable\n",
      "\u001b[0;31mTypeError\u001b[0m: iteration over a 0-d array"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(*zip(*enumerate(mean_step_loss)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abc'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"abc\"[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model_path = 'weights.pickle'\n",
    "\n",
    "with open(model_path, 'wb') as file:\n",
    "  pickle.dump(model_params, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_path, 'rb') as file:\n",
    "  model_params_pickle = pickle.load(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
